{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "853dc9a6-720e-4a2b-918e-c321c37bc998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:47:56] === STEP 1: Downloading zones (sequential with retries, cache & cool-down) ===\n",
      "[01:47:56] --- Starting zone: LISBOA ---\n",
      "[01:47:56] Loaded cached zone: raw_zones\\raw_LISBOA.csv (3931 rows)\n",
      "[01:47:56] --- Finished zone: LISBOA ---\n",
      "[01:47:56] Cooling down 30s before next zone ...\n",
      "[01:48:26] --- Starting zone: SINTRA ---\n",
      "[01:48:26] Loaded cached zone: raw_zones\\raw_SINTRA.csv (3931 rows)\n",
      "[01:48:26] --- Finished zone: SINTRA ---\n",
      "[01:48:26] Cooling down 30s before next zone ...\n",
      "[01:48:56] --- Starting zone: CASCAIS ---\n",
      "[01:48:56] Loaded cached zone: raw_zones\\raw_CASCAIS.csv (3931 rows)\n",
      "[01:48:56] --- Finished zone: CASCAIS ---\n",
      "[01:48:56] Cooling down 30s before next zone ...\n",
      "[01:49:26] --- Starting zone: LOURES ---\n",
      "[01:49:26] Loaded cached zone: raw_zones\\raw_LOURES.csv (3931 rows)\n",
      "[01:49:26] --- Finished zone: LOURES ---\n",
      "[01:49:26] Cooling down 30s before next zone ...\n",
      "[01:49:56] --- Starting zone: AMADORA ---\n",
      "[01:49:56] Loaded cached zone: raw_zones\\raw_AMADORA.csv (3931 rows)\n",
      "[01:49:56] --- Finished zone: AMADORA ---\n",
      "[01:49:56] Cooling down 30s before next zone ...\n",
      "[01:50:26] --- Starting zone: OEIRAS ---\n",
      "[01:50:26] Loaded cached zone: raw_zones\\raw_OEIRAS.csv (3931 rows)\n",
      "[01:50:26] --- Finished zone: OEIRAS ---\n",
      "[01:50:26] Cooling down 30s before next zone ...\n",
      "[01:50:56] --- Starting zone: ODIVELAS ---\n",
      "[01:50:56] Loaded cached zone: raw_zones\\raw_ODIVELAS.csv (3931 rows)\n",
      "[01:50:56] --- Finished zone: ODIVELAS ---\n",
      "[01:50:56] Cooling down 30s before next zone ...\n",
      "[01:51:26] --- Starting zone: VILA_FRANCA_DE_XIRA ---\n",
      "[01:51:26] Loaded cached zone: raw_zones\\raw_VILA_FRANCA_DE_XIRA.csv (3931 rows)\n",
      "[01:51:26] --- Finished zone: VILA_FRANCA_DE_XIRA ---\n",
      "[01:51:26] Cooling down 30s before next zone ...\n",
      "[01:51:56] --- Starting zone: MAFRA ---\n",
      "[01:51:56] Loaded cached zone: raw_zones\\raw_MAFRA.csv (3931 rows)\n",
      "[01:51:56] --- Finished zone: MAFRA ---\n",
      "[01:51:56] Cooling down 30s before next zone ...\n",
      "[01:52:26] --- Starting zone: TORRES_VEDRAS ---\n",
      "[01:52:26] Loaded cached zone: raw_zones\\raw_TORRES_VEDRAS.csv (3931 rows)\n",
      "[01:52:26] --- Finished zone: TORRES_VEDRAS ---\n",
      "[01:52:26] Cooling down 30s before next zone ...\n",
      "[01:52:56] --- Starting zone: MONTIJO ---\n",
      "[01:52:56] Loaded cached zone: raw_zones\\raw_MONTIJO.csv (3931 rows)\n",
      "[01:52:56] --- Finished zone: MONTIJO ---\n",
      "[01:52:56] Cooling down 30s before next zone ...\n",
      "[01:53:26] --- Starting zone: SANTARÉM ---\n",
      "[01:53:27] Loaded cached zone: raw_zones\\raw_SANTARÉM.csv (3931 rows)\n",
      "[01:53:27] --- Finished zone: SANTARÉM ---\n",
      "[01:53:27] Cooling down 30s before next zone ...\n",
      "[01:53:57] --- Starting zone: PORTO ---\n",
      "[01:53:57] Loaded cached zone: raw_zones\\raw_PORTO.csv (3931 rows)\n",
      "[01:53:57] --- Finished zone: PORTO ---\n",
      "[01:53:57] Cooling down 30s before next zone ...\n",
      "[01:54:27] --- Starting zone: VILA_NOVA_DE_GAIA ---\n",
      "[01:54:27] Loaded cached zone: raw_zones\\raw_VILA_NOVA_DE_GAIA.csv (3931 rows)\n",
      "[01:54:27] --- Finished zone: VILA_NOVA_DE_GAIA ---\n",
      "[01:54:27] Cooling down 30s before next zone ...\n",
      "[01:54:57] --- Starting zone: MATOSINHOS ---\n",
      "[01:54:57] Loaded cached zone: raw_zones\\raw_MATOSINHOS.csv (3931 rows)\n",
      "[01:54:57] --- Finished zone: MATOSINHOS ---\n",
      "[01:54:57] Cooling down 30s before next zone ...\n",
      "[01:55:27] --- Starting zone: GONDOMAR ---\n",
      "[01:55:27] Loaded cached zone: raw_zones\\raw_GONDOMAR.csv (3931 rows)\n",
      "[01:55:27] --- Finished zone: GONDOMAR ---\n",
      "[01:55:27] Cooling down 30s before next zone ...\n",
      "[01:55:57] --- Starting zone: MAIA ---\n",
      "[01:55:57] Loaded cached zone: raw_zones\\raw_MAIA.csv (3931 rows)\n",
      "[01:55:57] --- Finished zone: MAIA ---\n",
      "[01:55:57] Cooling down 30s before next zone ...\n",
      "[01:56:27] --- Starting zone: VALONGO ---\n",
      "[01:56:27] Loaded cached zone: raw_zones\\raw_VALONGO.csv (3931 rows)\n",
      "[01:56:27] --- Finished zone: VALONGO ---\n",
      "[01:56:27] Cooling down 30s before next zone ...\n",
      "[01:56:57] --- Starting zone: VILA_DO_CONDE ---\n",
      "[01:56:57] Loaded cached zone: raw_zones\\raw_VILA_DO_CONDE.csv (3931 rows)\n",
      "[01:56:57] --- Finished zone: VILA_DO_CONDE ---\n",
      "[01:56:57] Cooling down 30s before next zone ...\n",
      "[01:57:27] --- Starting zone: POVOA_DE_VARZIM ---\n",
      "[01:57:27] Loaded cached zone: raw_zones\\raw_POVOA_DE_VARZIM.csv (3931 rows)\n",
      "[01:57:27] --- Finished zone: POVOA_DE_VARZIM ---\n",
      "[01:57:27] Cooling down 30s before next zone ...\n",
      "[01:57:57] --- Starting zone: PAREDES ---\n",
      "[01:57:57] Loaded cached zone: raw_zones\\raw_PAREDES.csv (3931 rows)\n",
      "[01:57:57] --- Finished zone: PAREDES ---\n",
      "[01:57:57] Cooling down 30s before next zone ...\n",
      "[01:58:27] --- Starting zone: SANTO_TIRSO ---\n",
      "[01:58:27] Loaded cached zone: raw_zones\\raw_SANTO_TIRSO.csv (3931 rows)\n",
      "[01:58:27] --- Finished zone: SANTO_TIRSO ---\n",
      "[01:58:27] Cooling down 30s before next zone ...\n",
      "[01:58:57] --- Starting zone: PAÇOS_DE_FERREIRA ---\n",
      "[01:58:57] Loaded cached zone: raw_zones\\raw_PAÇOS_DE_FERREIRA.csv (3931 rows)\n",
      "[01:58:57] --- Finished zone: PAÇOS_DE_FERREIRA ---\n",
      "[01:58:57] Cooling down 30s before next zone ...\n",
      "[01:59:27] --- Starting zone: PENAFIEL ---\n",
      "[01:59:27] Loaded cached zone: raw_zones\\raw_PENAFIEL.csv (3931 rows)\n",
      "[01:59:27] --- Finished zone: PENAFIEL ---\n",
      "[01:59:27] Cooling down 30s before next zone ...\n",
      "[01:59:57] --- Starting zone: MIRANDELA ---\n",
      "[01:59:57] → Requesting MIRANDELA (41.4874, -7.187) ...\n",
      "[02:00:00] ✓ MIRANDELA: 3931 rows\n",
      "[02:00:00] Saved cache: raw_zones\\raw_MIRANDELA.csv\n",
      "[02:00:00] --- Finished zone: MIRANDELA ---\n",
      "[02:00:00] Cooling down 30s before next zone ...\n",
      "[02:00:30] --- Starting zone: MACEDO DE CAVALEIROS ---\n",
      "[02:00:30] → Requesting MACEDO DE CAVALEIROS (41.5382, -6.9611) ...\n",
      "[02:00:31] ✓ MACEDO DE CAVALEIROS: 3931 rows\n",
      "[02:00:31] Saved cache: raw_zones\\raw_MACEDO DE CAVALEIROS.csv\n",
      "[02:00:31] --- Finished zone: MACEDO DE CAVALEIROS ---\n",
      "[02:00:31] Cooling down 30s before next zone ...\n",
      "[02:01:01] --- Starting zone: BRAGA ---\n",
      "[02:01:01] Loaded cached zone: raw_zones\\raw_BRAGA.csv (3931 rows)\n",
      "[02:01:01] --- Finished zone: BRAGA ---\n",
      "[02:01:01] Cooling down 30s before next zone ...\n",
      "[02:01:31] --- Starting zone: GUIMARÃES ---\n",
      "[02:01:31] Loaded cached zone: raw_zones\\raw_GUIMARÃES.csv (3931 rows)\n",
      "[02:01:31] --- Finished zone: GUIMARÃES ---\n",
      "[02:01:31] Cooling down 30s before next zone ...\n",
      "[02:02:01] --- Starting zone: VILA_NOVA_DE_FAMALICAO ---\n",
      "[02:02:01] Loaded cached zone: raw_zones\\raw_VILA_NOVA_DE_FAMALICAO.csv (3931 rows)\n",
      "[02:02:01] --- Finished zone: VILA_NOVA_DE_FAMALICAO ---\n",
      "[02:02:01] Cooling down 30s before next zone ...\n",
      "[02:02:32] --- Starting zone: BARCELOS ---\n",
      "[02:02:32] Loaded cached zone: raw_zones\\raw_BARCELOS.csv (3931 rows)\n",
      "[02:02:32] --- Finished zone: BARCELOS ---\n",
      "[02:02:32] Cooling down 30s before next zone ...\n",
      "[02:03:02] --- Starting zone: VIANA_DO_CASTELO ---\n",
      "[02:03:02] Loaded cached zone: raw_zones\\raw_VIANA_DO_CASTELO.csv (3931 rows)\n",
      "[02:03:02] --- Finished zone: VIANA_DO_CASTELO ---\n",
      "[02:03:02] Cooling down 30s before next zone ...\n",
      "[02:03:32] --- Starting zone: FELGUEIRAS ---\n",
      "[02:03:32] Loaded cached zone: raw_zones\\raw_FELGUEIRAS.csv (3931 rows)\n",
      "[02:03:32] --- Finished zone: FELGUEIRAS ---\n",
      "[02:03:32] Cooling down 30s before next zone ...\n",
      "[02:04:02] --- Starting zone: VILA REAL ---\n",
      "[02:04:02] → Requesting VILA REAL (41.3006, -7.7441) ...\n",
      "[02:04:03] ✓ VILA REAL: 3931 rows\n",
      "[02:04:03] Saved cache: raw_zones\\raw_VILA REAL.csv\n",
      "[02:04:03] --- Finished zone: VILA REAL ---\n",
      "[02:04:03] Cooling down 30s before next zone ...\n",
      "[02:04:33] --- Starting zone: BRAGANÇA ---\n",
      "[02:04:33] → Requesting BRAGANÇA (41.8058, -6.7572) ...\n",
      "[02:04:35] ✓ BRAGANÇA: 3931 rows\n",
      "[02:04:35] Saved cache: raw_zones\\raw_BRAGANÇA.csv\n",
      "[02:04:35] --- Finished zone: BRAGANÇA ---\n",
      "[02:04:35] Cooling down 30s before next zone ...\n",
      "[02:05:05] --- Starting zone: COIMBRA ---\n",
      "[02:05:05] Loaded cached zone: raw_zones\\raw_COIMBRA.csv (3931 rows)\n",
      "[02:05:05] --- Finished zone: COIMBRA ---\n",
      "[02:05:05] Cooling down 30s before next zone ...\n",
      "[02:05:35] --- Starting zone: LEIRIA ---\n",
      "[02:05:35] Loaded cached zone: raw_zones\\raw_LEIRIA.csv (3931 rows)\n",
      "[02:05:35] --- Finished zone: LEIRIA ---\n",
      "[02:05:35] Cooling down 30s before next zone ...\n",
      "[02:06:05] --- Starting zone: VISEU ---\n",
      "[02:06:05] Loaded cached zone: raw_zones\\raw_VISEU.csv (3931 rows)\n",
      "[02:06:05] --- Finished zone: VISEU ---\n",
      "[02:06:05] Cooling down 30s before next zone ...\n",
      "[02:06:35] --- Starting zone: AVEIRO ---\n",
      "[02:06:35] Loaded cached zone: raw_zones\\raw_AVEIRO.csv (3931 rows)\n",
      "[02:06:35] --- Finished zone: AVEIRO ---\n",
      "[02:06:35] Cooling down 30s before next zone ...\n",
      "[02:07:05] --- Starting zone: SANTA_MARIA_DA_FEIRA ---\n",
      "[02:07:05] Loaded cached zone: raw_zones\\raw_SANTA_MARIA_DA_FEIRA.csv (3931 rows)\n",
      "[02:07:05] --- Finished zone: SANTA_MARIA_DA_FEIRA ---\n",
      "[02:07:05] Cooling down 30s before next zone ...\n",
      "[02:07:35] --- Starting zone: FIGUEIRA_DA_FOZ ---\n",
      "[02:07:35] Loaded cached zone: raw_zones\\raw_FIGUEIRA_DA_FOZ.csv (3931 rows)\n",
      "[02:07:35] --- Finished zone: FIGUEIRA_DA_FOZ ---\n",
      "[02:07:35] Cooling down 30s before next zone ...\n",
      "[02:08:05] --- Starting zone: OVAR ---\n",
      "[02:08:06] Loaded cached zone: raw_zones\\raw_OVAR.csv (3931 rows)\n",
      "[02:08:06] --- Finished zone: OVAR ---\n",
      "[02:08:06] Cooling down 30s before next zone ...\n",
      "[02:08:36] --- Starting zone: ALCOBAÇA ---\n",
      "[02:08:36] Loaded cached zone: raw_zones\\raw_ALCOBAÇA.csv (3931 rows)\n",
      "[02:08:36] --- Finished zone: ALCOBAÇA ---\n",
      "[02:08:36] Cooling down 30s before next zone ...\n",
      "[02:09:06] --- Starting zone: OLIVEIRA_DE_AZEMÉIS ---\n",
      "[02:09:06] Loaded cached zone: raw_zones\\raw_OLIVEIRA_DE_AZEMÉIS.csv (3931 rows)\n",
      "[02:09:06] --- Finished zone: OLIVEIRA_DE_AZEMÉIS ---\n",
      "[02:09:06] Cooling down 30s before next zone ...\n",
      "[02:09:36] --- Starting zone: SETÚBAL ---\n",
      "[02:09:36] Loaded cached zone: raw_zones\\raw_SETÚBAL.csv (3931 rows)\n",
      "[02:09:36] --- Finished zone: SETÚBAL ---\n",
      "[02:09:36] Cooling down 30s before next zone ...\n",
      "[02:10:06] --- Starting zone: ALMADA ---\n",
      "[02:10:06] Loaded cached zone: raw_zones\\raw_ALMADA.csv (3931 rows)\n",
      "[02:10:06] --- Finished zone: ALMADA ---\n",
      "[02:10:06] Cooling down 30s before next zone ...\n",
      "[02:10:36] --- Starting zone: SEIXAL ---\n",
      "[02:10:36] Loaded cached zone: raw_zones\\raw_SEIXAL.csv (3931 rows)\n",
      "[02:10:36] --- Finished zone: SEIXAL ---\n",
      "[02:10:36] Cooling down 30s before next zone ...\n",
      "[02:11:06] --- Starting zone: BARREIRO ---\n",
      "[02:11:06] Loaded cached zone: raw_zones\\raw_BARREIRO.csv (3931 rows)\n",
      "[02:11:06] --- Finished zone: BARREIRO ---\n",
      "[02:11:06] Cooling down 30s before next zone ...\n",
      "[02:11:36] --- Starting zone: PALMELA ---\n",
      "[02:11:36] Loaded cached zone: raw_zones\\raw_PALMELA.csv (3931 rows)\n",
      "[02:11:36] --- Finished zone: PALMELA ---\n",
      "[02:11:36] Cooling down 30s before next zone ...\n",
      "[02:12:06] --- Starting zone: MOITA ---\n",
      "[02:12:06] Loaded cached zone: raw_zones\\raw_MOITA.csv (3931 rows)\n",
      "[02:12:06] --- Finished zone: MOITA ---\n",
      "[02:12:06] Cooling down 30s before next zone ...\n",
      "[02:12:36] --- Starting zone: SESIMBRA ---\n",
      "[02:12:36] Loaded cached zone: raw_zones\\raw_SESIMBRA.csv (3931 rows)\n",
      "[02:12:36] --- Finished zone: SESIMBRA ---\n",
      "[02:12:36] Cooling down 30s before next zone ...\n",
      "[02:13:06] --- Starting zone: ÉVORA ---\n",
      "[02:13:06] Loaded cached zone: raw_zones\\raw_ÉVORA.csv (3931 rows)\n",
      "[02:13:06] --- Finished zone: ÉVORA ---\n",
      "[02:13:06] Cooling down 30s before next zone ...\n",
      "[02:13:36] --- Starting zone: FARO ---\n",
      "[02:13:36] Loaded cached zone: raw_zones\\raw_FARO.csv (3931 rows)\n",
      "[02:13:36] --- Finished zone: FARO ---\n",
      "[02:13:36] Cooling down 30s before next zone ...\n",
      "[02:14:06] --- Starting zone: LOULÉ ---\n",
      "[02:14:06] Loaded cached zone: raw_zones\\raw_LOULÉ.csv (3931 rows)\n",
      "[02:14:06] --- Finished zone: LOULÉ ---\n",
      "[02:14:06] Cooling down 30s before next zone ...\n",
      "[02:14:36] --- Starting zone: PORTIMÃO ---\n",
      "[02:14:36] Loaded cached zone: raw_zones\\raw_PORTIMÃO.csv (3931 rows)\n",
      "[02:14:36] --- Finished zone: PORTIMÃO ---\n",
      "[02:14:36] Cooling down 30s before next zone ...\n",
      "[02:15:06] ✓ Combined shape: 212,274 rows × 17 cols\n",
      "[02:15:06] === STEP 2: Cleaning and renaming columns ===\n",
      "[02:15:07] ✓ Columns standardized and converted to numeric.\n",
      "[02:15:07] === STEP 3: Creating derived variables (HDD, CDD, amplitude, day length) ===\n",
      "[02:15:07] ✓ Derived variables created.\n",
      "[02:15:07] === STEP 4: Adding calendar features (DOW, weekend, month, year, holidays, DST) ===\n",
      "[02:15:36] ✓ Calendar features added.\n",
      "[02:15:36] === STEP 5: Saving final dataset ===\n",
      "[02:15:43] Saved to: dataset_meteo_zonal.csv\n",
      "[02:15:43] Rows: 212,274 | Columns: 27\n",
      "[02:15:43] Done. Ready for feature analysis and regression!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script: build_meteo_dataset_retry_cooldown_resume.py\n",
    "Description:\n",
    "    Robust extractor for Open-Meteo daily archive with:\n",
    "      - Sequential per-zone processing\n",
    "      - Retries with exponential backoff + jitter\n",
    "      - Global cool-down between zones\n",
    "      - Per-zone CSV caching/resume (skip re-download if present)\n",
    "\n",
    "Requirements:\n",
    "    pip install pandas requests holidays tqdm\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import holidays\n",
    "\n",
    "# ----------------------------\n",
    "# Logging helper \n",
    "# ----------------------------\n",
    "def log(msg: str) -> None:\n",
    "    now = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(f\"[{now}] {msg}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG (adjust as needed)\n",
    "# ----------------------------\n",
    "ZONES = {\n",
    " \n",
    "    \"LISBOA\": (38.7167, -9.1333),  \n",
    "    \"SINTRA\": (38.801, -9.3783), \n",
    "    \"CASCAIS\": (38.6968, -9.4215), \n",
    "    \"LOURES\": (38.8309, -9.1684), \n",
    "    \"AMADORA\": (38.7538, -9.2308),\n",
    "    \"OEIRAS\": (38.691, -9.3109),\n",
    "    \"ODIVELAS\": (38.7927, -9.1838),\n",
    "    \"VILA_FRANCA_DE_XIRA\": (38.9552, -8.9897),\n",
    "    \"MAFRA\": (38.9379, -9.3276),\n",
    "    \"TORRES_VEDRAS\": (39.0911, -9.2586),\n",
    "    \"MONTIJO\": (38.7067, -8.9739),\n",
    "    \"SANTARÉM\": (39.2333, -8.6833),\n",
    "    \n",
    " \n",
    "    \"PORTO\": (41.1496, -8.611),\n",
    "    \"VILA_NOVA_DE_GAIA\": (41.124, -8.6124),\n",
    "    \"MATOSINHOS\": (41.1821, -8.6891),\n",
    "    \"GONDOMAR\": (41.1445, -8.5322), \n",
    "    \"MAIA\": (41.2357, -8.6199),\n",
    "    \"VALONGO\": (41.1888, -8.4986),\n",
    "    \"VILA_DO_CONDE\": (41.3533, -8.7452),\n",
    "    \"POVOA_DE_VARZIM\": (41.3834, -8.7636),\n",
    "    \"PAREDES\": (41.2049, -8.3315), \n",
    "    \"SANTO_TIRSO\": (41.3426, -8.4775),\n",
    "    \"PAÇOS_DE_FERREIRA\": (41.2766, -8.3762), \n",
    "    \"PENAFIEL\": (41.2084, -8.2828),\n",
    "    \"MIRANDELA\": (41.4874, -7.187),\n",
    "    \"MACEDO DE CAVALEIROS\": (41.5382, -6.9611),\n",
    "    \n",
    "   \n",
    "    \"BRAGA\": (41.5503, -8.42),\n",
    "    \"GUIMARÃES\": (41.4444, -8.2962),\n",
    "    \"VILA_NOVA_DE_FAMALICAO\": (41.408, -8.5198),\n",
    "    \"BARCELOS\": (41.5317, -8.6184),\n",
    "    \"VIANA_DO_CASTELO\": (41.6932, -8.8329),\n",
    "    \"FELGUEIRAS\": (41.3681, -8.194),\n",
    "    \"VILA REAL\": (41.3006, -7.7441),\n",
    "    \"BRAGANÇA\": (41.8058, -6.7572),\n",
    "    \n",
    "   \n",
    "    \"COIMBRA\": (40.2056, -8.4195),\n",
    "    \"LEIRIA\": (39.7436, -8.8071),\n",
    "    \"VISEU\": (40.661, -7.9097),\n",
    "    \"AVEIRO\": (40.6443, -8.6455),\n",
    "    \"SANTA_MARIA_DA_FEIRA\": (40.9273, -8.5484),\n",
    "    \"FIGUEIRA_DA_FOZ\": (40.1508, -8.8618),\n",
    "    \"OVAR\": (40.8586, -8.6251),\n",
    "    \"ALCOBAÇA\": (39.5522, -8.9775),\n",
    "    \"OLIVEIRA_DE_AZEMÉIS\": (40.841, -8.4756),\n",
    "    \n",
    "   \n",
    "    \"SETÚBAL\": (38.5244, -8.8882),\n",
    "    \"ALMADA\": (38.679, -9.1569),\n",
    "    \"SEIXAL\": (38.6401, -9.1014), \n",
    "    \"BARREIRO\": (38.6631, -9.0724),\n",
    "    \"PALMELA\": (38.569, -8.9013),\n",
    "    \"MOITA\": (38.6508, -8.9904),\n",
    "    \"SESIMBRA\": (38.4445, -9.1015), \n",
    "    \n",
    "    # Alentejo e Algarve\n",
    "    \"ÉVORA\": (38.5667, -7.9),\n",
    "    \"FARO\": (37.0187, -7.9272),\n",
    "    \"LOULÉ\": (37.1377, -8.0197),\n",
    "    \"PORTIMÃO\": (37.1369, -8.5378),\n",
    "}\n",
    "\n",
    "START_DATE = \"2015-01-01\"\n",
    "END_DATE   = \"2025-10-05\"\n",
    "TIMEZONE   = \"Europe/Lisbon\"\n",
    "\n",
    "DAILY_VARS = [\n",
    "    \"temperature_2m_max\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"temperature_2m_mean\",\n",
    "    \"precipitation_sum\",\n",
    "    \"wind_speed_10m_max\",\n",
    "    \"wind_gusts_10m_max\",\n",
    "    \"shortwave_radiation_sum\",\n",
    "    \"sunshine_duration\",\n",
    "    \"relative_humidity_2m_mean\",\n",
    "    \"cloudcover_mean\",\n",
    "    \"sunrise\",\n",
    "    \"sunset\",\n",
    "]\n",
    "\n",
    "RENAME_COLS = {\n",
    "    \"temperature_2m_max\": \"tmax_c\",\n",
    "    \"temperature_2m_min\": \"tmin_c\",\n",
    "    \"temperature_2m_mean\": \"tmean_c\",\n",
    "    \"precipitation_sum\": \"precip_mm\",\n",
    "    \"wind_speed_10m_max\": \"wind_speed_max\",\n",
    "    \"wind_gusts_10m_max\": \"wind_gusts_max\",\n",
    "    \"shortwave_radiation_sum\": \"rad_solar\",\n",
    "    \"sunshine_duration\": \"sunshine_sec\",\n",
    "    \"relative_humidity_2m_mean\": \"humidade_relativa\",\n",
    "    \"cloudcover_mean\": \"nebulosidade_media\",\n",
    "}\n",
    "\n",
    "# Retry / cooldown policy\n",
    "MAX_RETRIES_PER_ZONE = 10       # up to 10 attempts per zone\n",
    "BASE_WAIT_SECONDS    = 10       # exponential backoff base\n",
    "LONG_COOLDOWN_AFTER  = 5        # after this attempt, apply long cooldown\n",
    "LONG_COOLDOWN_SECONDS = 180     # 3 minutes cool-down if still rate-limited\n",
    "COOLDOWN_BETWEEN_ZONES = 30     # 30s after each successful zone\n",
    "STRICT_ABORT = True             # abort if a zone cannot be fetched after all retries\n",
    "\n",
    "OUTPUT_CSV = \"dataset_meteo_zonal.csv\"\n",
    "RAW_DIR = \"raw_zones\"           # per-zone cache directory\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def ensure_dir(path: str):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_zone_csv(df: pd.DataFrame, zone: str):\n",
    "    ensure_dir(RAW_DIR)\n",
    "    out_path = os.path.join(RAW_DIR, f\"raw_{zone}.csv\")\n",
    "    df.to_csv(out_path, index=False, float_format=\"%.3f\")\n",
    "    log(f\"Saved cache: {out_path}\")\n",
    "\n",
    "\n",
    "def load_zone_csv(zone: str) -> pd.DataFrame:\n",
    "    path = os.path.join(RAW_DIR, f\"raw_{zone}.csv\")\n",
    "    if os.path.isfile(path):\n",
    "        try:\n",
    "            df = pd.read_csv(path, parse_dates=[\"date\"])\n",
    "            log(f\"Loaded cached zone: {path} ({len(df)} rows)\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            log(f\"⚠ Failed to load cache for {zone}: {e}\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Single-zone request\n",
    "# ----------------------------\n",
    "def fetch_openmeteo_daily(lat: float, lon: float, zone: str, timeout: int = 60):\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": START_DATE,\n",
    "        \"end_date\": END_DATE,\n",
    "        \"daily\": \",\".join(DAILY_VARS),\n",
    "        \"timezone\": TIMEZONE,\n",
    "    }\n",
    "    log(f\"→ Requesting {zone} ({lat}, {lon}) ...\")\n",
    "    retry_after = 0\n",
    "    try:\n",
    "        r = requests.get(url, params=params, timeout=timeout)\n",
    "        retry_after = int(r.headers.get(\"Retry-After\", \"0\") or \"0\")\n",
    "    except Exception as e:\n",
    "        log(f\"✖ Network/connection error for {zone}: {e}\")\n",
    "        return pd.DataFrame(), None, 0\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        log(f\"✖ HTTP {r.status_code} for {zone}\")\n",
    "        return pd.DataFrame(), r.status_code, retry_after\n",
    "\n",
    "    data = r.json()\n",
    "    if \"daily\" not in data:\n",
    "        log(f\"⚠ No 'daily' key in response for {zone}\")\n",
    "        return pd.DataFrame(), 200, 0\n",
    "\n",
    "    df = pd.DataFrame(data[\"daily\"])\n",
    "    if \"time\" not in df.columns:\n",
    "        log(f\"⚠ Missing 'time' column for {zone}\")\n",
    "        return pd.DataFrame(), 200, 0\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"time\"])\n",
    "    df[\"zone\"] = zone\n",
    "    df[\"latitude\"] = lat\n",
    "    df[\"longitude\"] = lon\n",
    "    log(f\"✓ {zone}: {len(df)} rows\")\n",
    "    return df, 200, 0\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Retry wrapper (sequential)\n",
    "# ----------------------------\n",
    "def fetch_zone_with_retry(zone: str, lat: float, lon: float) -> pd.DataFrame:\n",
    "    # Try cache first\n",
    "    cached = load_zone_csv(zone)\n",
    "    if not cached.empty and cached[\"date\"].notna().any():\n",
    "        return cached\n",
    "\n",
    "    for attempt in range(1, MAX_RETRIES_PER_ZONE + 1):\n",
    "        df, status, retry_after = fetch_openmeteo_daily(lat, lon, zone, timeout=60)\n",
    "\n",
    "        if status == 200 and not df.empty:\n",
    "            save_zone_csv(df, zone)\n",
    "            return df\n",
    "\n",
    "        # decide waiting time\n",
    "        if status == 429 and retry_after > 0:\n",
    "            wait = retry_after + 1\n",
    "            log(f\"↻ Rate limited for {zone}. Respecting Retry-After: waiting {wait}s before retry #{attempt}.\")\n",
    "        else:\n",
    "            wait = BASE_WAIT_SECONDS * (2 ** (attempt - 1))\n",
    "            wait = int(wait + random.uniform(0, 1) * BASE_WAIT_SECONDS * 0.5)\n",
    "            log(f\"↻ Retry {attempt}/{MAX_RETRIES_PER_ZONE} for {zone} in {wait}s ...\")\n",
    "\n",
    "        # long cool-down after several failed attempts\n",
    "        if attempt == LONG_COOLDOWN_AFTER:\n",
    "            log(f\"⏳ Applying long cool-down of {LONG_COOLDOWN_SECONDS}s due to repeated rate limits/errors for {zone}.\")\n",
    "            time.sleep(LONG_COOLDOWN_SECONDS)\n",
    "\n",
    "        time.sleep(wait)\n",
    "\n",
    "    msg = f\"✖ Exhausted retries for {zone}.\"\n",
    "    if STRICT_ABORT:\n",
    "        log(msg + \" Aborting to avoid incomplete dataset.\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        log(msg + \" Skipping this zone and continuing.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 1: Download (sequential, with resume and cool-down)\n",
    "# ----------------------------\n",
    "log(\"=== STEP 1: Downloading zones (sequential with retries, cache & cool-down) ===\")\n",
    "tables = []\n",
    "for zone, (lat, lon) in ZONES.items():\n",
    "    log(f\"--- Starting zone: {zone} ---\")\n",
    "    df_zone = fetch_zone_with_retry(zone, lat, lon)\n",
    "    tables.append(df_zone)\n",
    "    log(f\"--- Finished zone: {zone} ---\")\n",
    "    log(f\"Cooling down {COOLDOWN_BETWEEN_ZONES}s before next zone ...\")\n",
    "    time.sleep(COOLDOWN_BETWEEN_ZONES)\n",
    "\n",
    "df = pd.concat(tables, ignore_index=True)\n",
    "df = df.sort_values([\"zone\", \"date\"]).reset_index(drop=True)\n",
    "log(f\"✓ Combined shape: {df.shape[0]:,} rows × {df.shape[1]} cols\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 2: Clean & rename\n",
    "# ----------------------------\n",
    "log(\"=== STEP 2: Cleaning and renaming columns ===\")\n",
    "df = df.rename(columns=RENAME_COLS)\n",
    "for col in RENAME_COLS.values():\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "log(\"✓ Columns standardized and converted to numeric.\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 3: Derived variables\n",
    "# ----------------------------\n",
    "log(\"=== STEP 3: Creating derived variables (HDD, CDD, amplitude, day length) ===\")\n",
    "if \"tmean_c\" in df.columns:\n",
    "    df[\"HDD18\"] = (18 - df[\"tmean_c\"]).clip(lower=0)\n",
    "    df[\"CDD22\"] = (df[\"tmean_c\"] - 22).clip(lower=0)\n",
    "else:\n",
    "    df[\"HDD18\"] = pd.NA\n",
    "    df[\"CDD22\"] = pd.NA\n",
    "\n",
    "if {\"tmax_c\", \"tmin_c\"}.issubset(df.columns):\n",
    "    df[\"amp_termica\"] = df[\"tmax_c\"] - df[\"tmin_c\"]\n",
    "else:\n",
    "    df[\"amp_termica\"] = pd.NA\n",
    "\n",
    "if {\"sunrise\", \"sunset\"}.issubset(df.columns):\n",
    "    df[\"sunrise\"] = pd.to_datetime(df[\"sunrise\"], errors=\"coerce\")\n",
    "    df[\"sunset\"]  = pd.to_datetime(df[\"sunset\"],  errors=\"coerce\")\n",
    "    df[\"day_length_hours\"] = ((df[\"sunset\"] - df[\"sunrise\"]).dt.total_seconds() / 3600).round(2)\n",
    "else:\n",
    "    df[\"day_length_hours\"] = pd.NA\n",
    "\n",
    "log(\"✓ Derived variables created.\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 4: Calendar features\n",
    "# ----------------------------\n",
    "log(\"=== STEP 4: Adding calendar features (DOW, weekend, month, year, holidays, DST) ===\")\n",
    "df[\"dow\"] = df[\"date\"].dt.dayofweek\n",
    "df[\"is_weekend\"] = df[\"dow\"].isin([5, 6]).astype(int)\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "df[\"year\"] = df[\"date\"].dt.year\n",
    "\n",
    "try:\n",
    "    pt_holidays = holidays.Portugal()\n",
    "    df[\"is_holiday\"] = df[\"date\"].isin(pt_holidays).astype(int)\n",
    "except Exception as e:\n",
    "    log(f\"⚠ Holidays feature failed: {e}\")\n",
    "    df[\"is_holiday\"] = 0\n",
    "\n",
    "try:\n",
    "    df[\"is_dst\"] = df[\"date\"].apply(lambda d: bool(pd.Timestamp(d, tz=\"Europe/Lisbon\").dst()))\n",
    "except Exception as e:\n",
    "    log(f\"⚠ DST feature failed: {e}\")\n",
    "    df[\"is_dst\"] = 0\n",
    "\n",
    "log(\"✓ Calendar features added.\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 5: Save\n",
    "# ----------------------------\n",
    "log(\"=== STEP 5: Saving final dataset ===\")\n",
    "df.to_csv(OUTPUT_CSV, index=False, float_format=\"%.3f\")\n",
    "log(f\"Saved to: {OUTPUT_CSV}\")\n",
    "log(f\"Rows: {df.shape[0]:,} | Columns: {df.shape[1]}\")\n",
    "log(\"Done. Ready for feature analysis and regression!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b930aeb7-85de-4864-8962-d40c924c340a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A iniciar o merge final...\n",
      "\n",
      "--------------------------------------------------\n",
      "✅ SUCESS! FINALIZED DATABASE!\n",
      "The final delivery file ‘dataset_meteo_com_consumo.csv’ was created with 212274 rows and 28 columns.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "print(\"Starting the final merge...\")\n",
    "\n",
    "\n",
    "files_needed = ['dataset_meteo_zonal.csv', 'target_consumo.csv']\n",
    "for f in files_needed:\n",
    "    if not os.path.exists(f):\n",
    "        print(f\"ERROR: File '{f}' not found. Ensure that the consumption file is in the folder and is named 'target_consumo.csv'.\")\n",
    "        exit()\n",
    "\n",
    "try:\n",
    "    \n",
    "    df_meteo = pd.read_csv('dataset_meteo_zonal.csv')\n",
    "   \n",
    "    df_consumo = pd.read_csv('target_consumo.csv') \n",
    "except Exception as e:\n",
    "    print(f\"ERROR loading files: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "df_meteo['date'] = pd.to_datetime(df_meteo['date'])\n",
    "df_consumo['date'] = pd.to_datetime(df_consumo['date']) \n",
    "\n",
    "\n",
    "df_consumo.rename(columns={'date': 'date'}, inplace=True)\n",
    "\n",
    "\n",
    "df_final = pd.merge(\n",
    "    df_meteo,\n",
    "    df_consumo,\n",
    "    on='date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "df_final.sort_values(by=['date', 'zone'], inplace=True)\n",
    "df_final.to_csv('dataset_meteo_com_consumo.csv', index=False, float_format=\"%.3f\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "print(\"✅ SUCCESS! DATABASE COMPLETED!\")\n",
    "print(f\"The final delivery file ‘dataset_meteo_com_consumo.csv’ was created with {len(df_final):,} lines and {df_final.shape[1]} columns.\")\n",
    "print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
